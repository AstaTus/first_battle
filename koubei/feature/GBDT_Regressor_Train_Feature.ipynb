{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import time\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sys import path\n",
    "path.append(r'E:\\data_mining\\project\\IJCAI-17-口碑\\koubei')\n",
    "\n",
    "import predict\n",
    "import base\n",
    "import shop_classify as sc\n",
    "\n",
    "import matplotlib\n",
    "myfont = matplotlib.font_manager.FontProperties(fname=r'C:/Windows/Fonts/msyh.ttf')\n",
    "matplotlib.use('qt4agg')  \n",
    "#指定默认字体  \n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']   \n",
    "matplotlib.rcParams['font.family']='sans-serif'  \n",
    "#解决负号'-'显示为方块的问题  \n",
    "matplotlib.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取休假表\n",
    "calenders = base.ReadCalendarCSV();\n",
    "#读取user_pay_count\n",
    "user_pay_counts = base.ReadUserPayCountCSV();\n",
    "\n",
    "##读取城市名称对照表\n",
    "city_names = base.ReadCityNameCSV();\n",
    "#读取开店时间数据\n",
    "shop_open_dates = base.ReadShopOpenDateCSV();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###读取商家信息\n",
    "shop_infos = base.ReadProcessShopInfoCSV();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initWeekDate(start_time, stop_time):\n",
    "    train_group_time_ranges = []\n",
    "    while(start_time <= stop_time):\n",
    "        X_end_time = start_time + datetime.timedelta(weeks=2, days=6)\n",
    "        y_start_time = start_time + datetime.timedelta(weeks=3)\n",
    "        y_end_time = y_start_time + datetime.timedelta(days=6)\n",
    "        \n",
    "        train_group_time_ranges.append([pd.date_range(start=start_time, end=X_end_time, freq='D'), pd.date_range(start=y_start_time, end=y_end_time, freq='D')])\n",
    "        \n",
    "        start_time = start_time + datetime.timedelta(weeks=1)\n",
    "\n",
    "    return train_group_time_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = pd.to_datetime('2016-6-7')\n",
    "stop_time = pd.to_datetime('2016-10-31') - datetime.timedelta(weeks=3, days=6)\n",
    "#stop_time = pd.to_datetime('2016-10-31') - datetime.timedelta(weeks=3, days=6)\n",
    "time_ranges = initWeekDate(start_time, stop_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pay_counts = pd.read_csv(\"../data/train/fill_sliding_window_data.txt\", sep=\"\\t\", encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pay_counts.columns = train_pay_counts.columns.map(lambda str_date:datetime.datetime.strptime(str_date, \"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateSingleHolidayMeanData(id, shop_open_dates, train_pay_counts, calenders, week):\n",
    "    df = train_pay_counts.loc[id][np.array(range(week * 7, (week + 1) * 7))].T;\n",
    "    df = df.to_frame();\n",
    "    df.columns = ['count']\n",
    "    df['holiday'] = calenders.loc[df.index.strftime('%Y-%m-%d')]['daytype'].values\n",
    "        \n",
    "    params = {}\n",
    "    \n",
    "    params['w_' + str(week) + '_mean'] = df['count'].mean()\n",
    "    params['w_' + str(week) + '_std'] = df['count'].std()\n",
    "    params['w_' + str(week) + '_max'] = df['count'].max()\n",
    "    params['w_' + str(week) + '_min'] = df['count'].min()\n",
    "    params['w_' + str(week) + '_median'] = df['count'].median()\n",
    "    params['w_' + str(week) + '_mad'] = df['count'].mad()\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "            temp_df = df[df['holiday'] == i];\n",
    "            if len(temp_df) == 0:\n",
    "                params['w_' + str(week) + '_daytype_mean_' + str(i)] = params['w_' + str(week) + '_mean']\n",
    "            else:\n",
    "                params['w_' + str(week) + '_daytype_mean_' + str(i)] = temp_df['count'].mean()\n",
    "            \n",
    "    return params;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_shop_num = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateHolidayMeansData(shop_open_dates, train_pay_counts, calenders):\n",
    "    shop_param_dict = {}\n",
    "    for id in range(1,max_shop_num):\n",
    "        param_dict = {}\n",
    "        for week in range(3):\n",
    "            params = calculateSingleHolidayMeanData(id, shop_open_dates, train_pay_counts, calenders, week)\n",
    "            param_dict.update(params)\n",
    "\n",
    "        ######################################################################################\n",
    "        all_week_counts = train_pay_counts.loc[id][np.array(range(0, 21))].T.to_frame();\n",
    "        all_week_counts.columns = ['count']\n",
    "        #print(all_week_counts)\n",
    "        all_week_counts['holiday'] = calenders.loc[all_week_counts.index.strftime('%Y-%m-%d')]['daytype'].values\n",
    "        \n",
    "        params = {}\n",
    "        params['all_mean'] = all_week_counts['count'].mean()\n",
    "        params['all_std'] = all_week_counts['count'].std()\n",
    "        params['all_max'] = all_week_counts['count'].max()\n",
    "        params['all_min'] = all_week_counts['count'].min()\n",
    "        params['all_median'] = all_week_counts['count'].median()\n",
    "        params['all_mad'] = all_week_counts['count'].mad()\n",
    "    \n",
    "        for i in range(1, 6):\n",
    "            temp_df = all_week_counts[all_week_counts['holiday'] == i];\n",
    "            if len(temp_df) == 0:\n",
    "                params['all_daytype_mean_' + str(i)] = params['all_mean']\n",
    "                params['all_daytype_all_max_' + str(i)] = params['all_max']\n",
    "                params['all_daytype_all_min_' + str(i)] = params['all_min']\n",
    "                params['all_daytype_all_median_' + str(i)] = params['all_median']\n",
    "                params['all_daytype_all_mad_' + str(i)] = params['all_mad']\n",
    "            else:\n",
    "                params['all_daytype_mean_' + str(i)] = temp_df['count'].mean()\n",
    "                params['all_daytype_max_' + str(i)] = temp_df['count'].max()\n",
    "                params['all_daytype_min_' + str(i)] = temp_df['count'].min()\n",
    "                params['all_daytype_median_' + str(i)] = temp_df['count'].median()\n",
    "                params['all_daytype_mad_' + str(i)] = temp_df['count'].mad()\n",
    "                \n",
    "            if len(temp_df) <= 1:\n",
    "                params['all_daytype_all_std_' + str(i)] = params['all_std']\n",
    "            else:\n",
    "                params['all_daytype_std_' + str(i)] = temp_df['count'].std()\n",
    "                \n",
    "        param_dict.update(params)\n",
    "                \n",
    "        shop_param_dict[id] = param_dict;\n",
    "    return shop_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-06-07', '2016-06-08', '2016-06-09', '2016-06-10',\n",
      "               '2016-06-11', '2016-06-12', '2016-06-13', '2016-06-14',\n",
      "               '2016-06-15', '2016-06-16', '2016-06-17', '2016-06-18',\n",
      "               '2016-06-19', '2016-06-20', '2016-06-21', '2016-06-22',\n",
      "               '2016-06-23', '2016-06-24', '2016-06-25', '2016-06-26',\n",
      "               '2016-06-27'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-06-14', '2016-06-15', '2016-06-16', '2016-06-17',\n",
      "               '2016-06-18', '2016-06-19', '2016-06-20', '2016-06-21',\n",
      "               '2016-06-22', '2016-06-23', '2016-06-24', '2016-06-25',\n",
      "               '2016-06-26', '2016-06-27', '2016-06-28', '2016-06-29',\n",
      "               '2016-06-30', '2016-07-01', '2016-07-02', '2016-07-03',\n",
      "               '2016-07-04'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-06-21', '2016-06-22', '2016-06-23', '2016-06-24',\n",
      "               '2016-06-25', '2016-06-26', '2016-06-27', '2016-06-28',\n",
      "               '2016-06-29', '2016-06-30', '2016-07-01', '2016-07-02',\n",
      "               '2016-07-03', '2016-07-04', '2016-07-05', '2016-07-06',\n",
      "               '2016-07-07', '2016-07-08', '2016-07-09', '2016-07-10',\n",
      "               '2016-07-11'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-06-28', '2016-06-29', '2016-06-30', '2016-07-01',\n",
      "               '2016-07-02', '2016-07-03', '2016-07-04', '2016-07-05',\n",
      "               '2016-07-06', '2016-07-07', '2016-07-08', '2016-07-09',\n",
      "               '2016-07-10', '2016-07-11', '2016-07-12', '2016-07-13',\n",
      "               '2016-07-14', '2016-07-15', '2016-07-16', '2016-07-17',\n",
      "               '2016-07-18'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-07-05', '2016-07-06', '2016-07-07', '2016-07-08',\n",
      "               '2016-07-09', '2016-07-10', '2016-07-11', '2016-07-12',\n",
      "               '2016-07-13', '2016-07-14', '2016-07-15', '2016-07-16',\n",
      "               '2016-07-17', '2016-07-18', '2016-07-19', '2016-07-20',\n",
      "               '2016-07-21', '2016-07-22', '2016-07-23', '2016-07-24',\n",
      "               '2016-07-25'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-07-12', '2016-07-13', '2016-07-14', '2016-07-15',\n",
      "               '2016-07-16', '2016-07-17', '2016-07-18', '2016-07-19',\n",
      "               '2016-07-20', '2016-07-21', '2016-07-22', '2016-07-23',\n",
      "               '2016-07-24', '2016-07-25', '2016-07-26', '2016-07-27',\n",
      "               '2016-07-28', '2016-07-29', '2016-07-30', '2016-07-31',\n",
      "               '2016-08-01'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-07-19', '2016-07-20', '2016-07-21', '2016-07-22',\n",
      "               '2016-07-23', '2016-07-24', '2016-07-25', '2016-07-26',\n",
      "               '2016-07-27', '2016-07-28', '2016-07-29', '2016-07-30',\n",
      "               '2016-07-31', '2016-08-01', '2016-08-02', '2016-08-03',\n",
      "               '2016-08-04', '2016-08-05', '2016-08-06', '2016-08-07',\n",
      "               '2016-08-08'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-07-26', '2016-07-27', '2016-07-28', '2016-07-29',\n",
      "               '2016-07-30', '2016-07-31', '2016-08-01', '2016-08-02',\n",
      "               '2016-08-03', '2016-08-04', '2016-08-05', '2016-08-06',\n",
      "               '2016-08-07', '2016-08-08', '2016-08-09', '2016-08-10',\n",
      "               '2016-08-11', '2016-08-12', '2016-08-13', '2016-08-14',\n",
      "               '2016-08-15'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-08-02', '2016-08-03', '2016-08-04', '2016-08-05',\n",
      "               '2016-08-06', '2016-08-07', '2016-08-08', '2016-08-09',\n",
      "               '2016-08-10', '2016-08-11', '2016-08-12', '2016-08-13',\n",
      "               '2016-08-14', '2016-08-15', '2016-08-16', '2016-08-17',\n",
      "               '2016-08-18', '2016-08-19', '2016-08-20', '2016-08-21',\n",
      "               '2016-08-22'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-08-09', '2016-08-10', '2016-08-11', '2016-08-12',\n",
      "               '2016-08-13', '2016-08-14', '2016-08-15', '2016-08-16',\n",
      "               '2016-08-17', '2016-08-18', '2016-08-19', '2016-08-20',\n",
      "               '2016-08-21', '2016-08-22', '2016-08-23', '2016-08-24',\n",
      "               '2016-08-25', '2016-08-26', '2016-08-27', '2016-08-28',\n",
      "               '2016-08-29'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-08-16', '2016-08-17', '2016-08-18', '2016-08-19',\n",
      "               '2016-08-20', '2016-08-21', '2016-08-22', '2016-08-23',\n",
      "               '2016-08-24', '2016-08-25', '2016-08-26', '2016-08-27',\n",
      "               '2016-08-28', '2016-08-29', '2016-08-30', '2016-08-31',\n",
      "               '2016-09-01', '2016-09-02', '2016-09-03', '2016-09-04',\n",
      "               '2016-09-05'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-08-23', '2016-08-24', '2016-08-25', '2016-08-26',\n",
      "               '2016-08-27', '2016-08-28', '2016-08-29', '2016-08-30',\n",
      "               '2016-08-31', '2016-09-01', '2016-09-02', '2016-09-03',\n",
      "               '2016-09-04', '2016-09-05', '2016-09-06', '2016-09-07',\n",
      "               '2016-09-08', '2016-09-09', '2016-09-10', '2016-09-11',\n",
      "               '2016-09-12'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-08-30', '2016-08-31', '2016-09-01', '2016-09-02',\n",
      "               '2016-09-03', '2016-09-04', '2016-09-05', '2016-09-06',\n",
      "               '2016-09-07', '2016-09-08', '2016-09-09', '2016-09-10',\n",
      "               '2016-09-11', '2016-09-12', '2016-09-13', '2016-09-14',\n",
      "               '2016-09-15', '2016-09-16', '2016-09-17', '2016-09-18',\n",
      "               '2016-09-19'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-09-06', '2016-09-07', '2016-09-08', '2016-09-09',\n",
      "               '2016-09-10', '2016-09-11', '2016-09-12', '2016-09-13',\n",
      "               '2016-09-14', '2016-09-15', '2016-09-16', '2016-09-17',\n",
      "               '2016-09-18', '2016-09-19', '2016-09-20', '2016-09-21',\n",
      "               '2016-09-22', '2016-09-23', '2016-09-24', '2016-09-25',\n",
      "               '2016-09-26'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-09-13', '2016-09-14', '2016-09-15', '2016-09-16',\n",
      "               '2016-09-17', '2016-09-18', '2016-09-19', '2016-09-20',\n",
      "               '2016-09-21', '2016-09-22', '2016-09-23', '2016-09-24',\n",
      "               '2016-09-25', '2016-09-26', '2016-09-27', '2016-09-28',\n",
      "               '2016-09-29', '2016-09-30', '2016-10-01', '2016-10-02',\n",
      "               '2016-10-03'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-09-20', '2016-09-21', '2016-09-22', '2016-09-23',\n",
      "               '2016-09-24', '2016-09-25', '2016-09-26', '2016-09-27',\n",
      "               '2016-09-28', '2016-09-29', '2016-09-30', '2016-10-01',\n",
      "               '2016-10-02', '2016-10-03', '2016-10-04', '2016-10-05',\n",
      "               '2016-10-06', '2016-10-07', '2016-10-08', '2016-10-09',\n",
      "               '2016-10-10'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-09-27', '2016-09-28', '2016-09-29', '2016-09-30',\n",
      "               '2016-10-01', '2016-10-02', '2016-10-03', '2016-10-04',\n",
      "               '2016-10-05', '2016-10-06', '2016-10-07', '2016-10-08',\n",
      "               '2016-10-09', '2016-10-10', '2016-10-11', '2016-10-12',\n",
      "               '2016-10-13', '2016-10-14', '2016-10-15', '2016-10-16',\n",
      "               '2016-10-17'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n",
      "DatetimeIndex(['2016-10-04', '2016-10-05', '2016-10-06', '2016-10-07',\n",
      "               '2016-10-08', '2016-10-09', '2016-10-10', '2016-10-11',\n",
      "               '2016-10-12', '2016-10-13', '2016-10-14', '2016-10-15',\n",
      "               '2016-10-16', '2016-10-17', '2016-10-18', '2016-10-19',\n",
      "               '2016-10-20', '2016-10-21', '2016-10-22', '2016-10-23',\n",
      "               '2016-10-24'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "shop_mean_dict\n"
     ]
    }
   ],
   "source": [
    "all_X_train_df = None\n",
    "all_y_train_df = None\n",
    "is_first_batch = True\n",
    "\n",
    "for tr in time_ranges:\n",
    "    X_train_data = train_pay_counts[tr[0]]\n",
    "    y_train_data = train_pay_counts[tr[1]]\n",
    "    print(tr[0])\n",
    "    print('shop_mean_dict')\n",
    "    shop_mean_dict = calculateHolidayMeansData(shop_open_dates, X_train_data, calenders)\n",
    "    ########################################################################################\n",
    "    X_train_df = pd.DataFrame(shop_mean_dict)\n",
    "    X_train_df = X_train_df.T\n",
    "    #前三周数据\n",
    "    ############################################################################################\n",
    "    X_train_df = pd.merge(X_train_df, X_train_data, left_index=True, right_index=True)\n",
    "    \n",
    "    ############################################################################################\n",
    "    \n",
    "    #poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "    #X_train_df = pd.merge(X_train_df, shop_infos[['score', 'shop_level', 'per_pay']], how='inner', left_on='id', right_index=True)\n",
    "\n",
    "    #X_train_id_df = X_train_df['id']\n",
    "    #X_train_df = X_train_df.drop('id', axis=1)\n",
    "\n",
    "    #X_train_poly = poly.fit_transform(X_train_df.values)\n",
    "    X_train_scaled = preprocessing.scale(X_train_df)\n",
    "    X_train_df = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "    #X_train_df['id'] = X_train_id_df\n",
    "\n",
    "    #X_train_df = pd.merge(X_train_df, shop_infos.drop(['score', 'shop_level', 'per_pay'], axis=1), how='inner', left_on='id',right_index=True)\n",
    "    #X_train_w1_df = X_train_w1_df.astype(np.int)\n",
    "    #X_train_df = X_train_df.drop(['id'], axis=1)\n",
    "    \n",
    "    \n",
    "    y_train_data.columns=np.array(range(7))\n",
    "    y_train_df = y_train_data\n",
    "    \n",
    "    \n",
    "    if is_first_batch == True:\n",
    "        all_X_train_df = X_train_df\n",
    "        all_y_train_df = y_train_df\n",
    "        is_first_batch = False\n",
    "    else:\n",
    "        #print(all_X_train_df)\n",
    "        all_X_train_df = pd.concat([all_X_train_df, X_train_df])\n",
    "        all_y_train_df = pd.concat([all_y_train_df, y_train_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_X_train_df.to_csv(\"../data/train/gbdt/X_train.txt\", sep='\\t', index=True, encoding='UTF-8')\n",
    "all_y_train_df.to_csv(\"../data/train/gbdt/y_train.txt\", sep='\\t', header= None, index=True, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=26, step=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X_train_df.columns"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
